{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_nets import VGG16Plus, VGG16PlusPlus\n",
    "from vgg_nets import VGG8\n",
    "import datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_nets import VGG8OnOff, VGG8OnOffNoReduction, VGG8FullOnOff\n",
    "# load in data\n",
    "x_train, y_train, x_val, y_val, x_test, y_test, classnames = datasets.get_dataset('cifar10', val_prop=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\alexl\\miniconda3\\envs\\tf_new\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Dense layer output(output) shape: [1, 10]\n",
      "dense_block:\n",
      "\tDropout layer output(dense_block/dropout_layer_0) shape: [1, 512]\n",
      "\tDense layer output(dense_block/dense_layer_0) shape: [1, 512]\n",
      "Flatten layer output(flatten) shape: [1, 8192]\n",
      "conv_block_3:\n",
      "\tDropout layer output(conv_block_3/dropout_layer_1) shape: [1, 4, 4, 512]\n",
      "\tMaxPool2D layer output(conv_block_3/max_pool_on_off_layer_1) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_1) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_0) shape: [1, 8, 8, 256]\n",
      "conv_block_2:\n",
      "\tDropout layer output(conv_block_2/dropout_layer_1) shape: [1, 8, 8, 256]\n",
      "\tMaxPool2D layer output(conv_block_2/max_pool_on_off_layer_1) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(conv_block_2/conv_layer_1) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(conv_block_2/conv_layer_0) shape: [1, 16, 16, 128]\n",
      "conv_block_1:\n",
      "\tDropout layer output(conv_block_1/dropout_layer_1) shape: [1, 16, 16, 128]\n",
      "\tMaxPool2D layer output(conv_block_1/max_pool_on_off_layer_1) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(conv_block_1/conv_layer_1) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(conv_block_1/conv_layer_0) shape: [1, 32, 32, 64]\n",
      "---------------------------------------------------------------------------\n",
      "Starting training with patience=10...\n",
      "Epoch 1/10000: Train Loss: 1.6763, Val Loss: 1.2697, Val Acc: 0.5393, Time: 37.05s\n",
      "Epoch 2/10000: Train Loss: 1.1682, Val Loss: 1.0067, Val Acc: 0.6517, Time: 34.70s\n",
      "Epoch 3/10000: Train Loss: 0.9201, Val Loss: 0.8338, Val Acc: 0.7043, Time: 34.70s\n",
      "Epoch 4/10000: Train Loss: 0.7717, Val Loss: 0.7218, Val Acc: 0.7491, Time: 34.74s\n",
      "Epoch 5/10000: Train Loss: 0.6663, Val Loss: 0.7075, Val Acc: 0.7605, Time: 34.80s\n",
      "Epoch 6/10000: Train Loss: 0.6028, Val Loss: 0.6407, Val Acc: 0.7797, Time: 35.14s\n",
      "Epoch 7/10000: Train Loss: 0.5472, Val Loss: 0.6171, Val Acc: 0.7916, Time: 35.15s\n",
      "Epoch 8/10000: Train Loss: 0.4892, Val Loss: 0.6020, Val Acc: 0.7979, Time: 34.96s\n",
      "Epoch 9/10000: Train Loss: 0.4588, Val Loss: 0.6038, Val Acc: 0.7933, Time: 34.92s\n",
      "Epoch 10/10000: Train Loss: 0.4267, Val Loss: 0.6121, Val Acc: 0.7952, Time: 34.86s\n",
      "Epoch 11/10000: Train Loss: 0.4159, Val Loss: 0.5968, Val Acc: 0.8026, Time: 35.27s\n",
      "Epoch 12/10000: Train Loss: 0.3951, Val Loss: 0.5882, Val Acc: 0.8040, Time: 34.71s\n",
      "Epoch 13/10000: Train Loss: 0.3654, Val Loss: 0.5761, Val Acc: 0.8093, Time: 34.77s\n",
      "Epoch 14/10000: Train Loss: 0.3498, Val Loss: 0.5272, Val Acc: 0.8198, Time: 35.03s\n",
      "Epoch 15/10000: Train Loss: 0.3538, Val Loss: 0.6137, Val Acc: 0.8055, Time: 35.25s\n",
      "Epoch 16/10000: Train Loss: 0.3465, Val Loss: 0.5604, Val Acc: 0.8153, Time: 34.88s\n",
      "Epoch 17/10000: Train Loss: 0.3228, Val Loss: 0.5808, Val Acc: 0.8101, Time: 34.92s\n",
      "Epoch 18/10000: Train Loss: 0.3167, Val Loss: 0.6523, Val Acc: 0.7938, Time: 34.87s\n",
      "Epoch 19/10000: Train Loss: 0.3182, Val Loss: 0.5754, Val Acc: 0.8139, Time: 35.21s\n",
      "Epoch 20/10000: Train Loss: 0.3058, Val Loss: 0.5638, Val Acc: 0.8204, Time: 34.73s\n",
      "Epoch 21/10000: Train Loss: 0.3050, Val Loss: 0.5706, Val Acc: 0.8192, Time: 34.89s\n",
      "Epoch 22/10000: Train Loss: 0.3069, Val Loss: 0.5611, Val Acc: 0.8229, Time: 34.93s\n",
      "Epoch 23/10000: Train Loss: 0.2877, Val Loss: 0.5647, Val Acc: 0.8230, Time: 35.24s\n",
      "Finished training after 23 epochs!\n",
      "805.718620300293\n",
      "test_acc: 0.817307710647583\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and clear session\n",
    "tf.random.set_seed(0)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = VGG8FullOnOff(C=10, \n",
    "            input_feats_shape=x_train.shape[1:], \n",
    "            wt_init=\"he\",\n",
    "            reg=0.6,\n",
    "            conv_dropout=True)\n",
    "\n",
    "# Set loss function and compile model\n",
    "model.compile(loss='cross_entropy', optimizer=\"adamw\", lr=0.001)\n",
    "\n",
    "print(f\"Starting training with patience={10}...\")\n",
    "\n",
    "start_total = time.time()\n",
    "\n",
    "# Train the model\n",
    "train_loss_hist, val_loss_hist, val_acc_hist, e = model.fit(\n",
    "    x_train, y_train, x_val, y_val, patience=10)\n",
    "\n",
    "total_time = time.time() - start_total\n",
    "\n",
    "# Evaluate on test set\n",
    "test_acc, test_loss = model.evaluate(x_test, y_test, batch_sz=128)\n",
    "print(total_time)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
