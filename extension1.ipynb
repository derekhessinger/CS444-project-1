{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_nets import VGG4Plus, VGG15, VGG15Plus, VGG15PlusPlus, VGG16Plus, VGG16PlusPlus\n",
    "from vgg_nets import VGG8, VGG8OnOff, VGG8OnOffNoReduction, VGG15PlusPlusOffOn, VGG15PlusPlusOffOn\n",
    "from datasets import get_dataset\n",
    "import datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Training VGG15PlusPlusOffOn ====================\n",
      "---------------------------------------------------------------------------\n",
      "Dense layer output(output) shape: [1, 10]\n",
      "dense_block:\n",
      "\tDropout layer output(dense_block/dropout_layer_0) shape: [1, 512]\n",
      "\tDense layer output(dense_block/dense_layer_0) shape: [1, 512]\n",
      "Flatten layer output(flatten) shape: [1, 512]\n",
      "conv_block_5:\n",
      "\tDropout layer output(conv_block_5/dropout_layer_2) shape: [1, 1, 1, 512]\n",
      "\tMaxPool2D layer output(conv_block_5/max_pool_layer_2) shape: [1, 1, 1, 512]\n",
      "\tConv2D layer output(conv_block_5/conv_layer_2) shape: [1, 2, 2, 512]\n",
      "\tConv2D layer output(conv_block_5/conv_layer_1) shape: [1, 2, 2, 512]\n",
      "\tConv2D layer output(conv_block_5/conv_layer_0) shape: [1, 2, 2, 512]\n",
      "conv_block_4:\n",
      "\tDropout layer output(conv_block_4/dropout_layer_2) shape: [1, 2, 2, 512]\n",
      "\tMaxPool2D layer output(conv_block_4/max_pool_layer_2) shape: [1, 2, 2, 512]\n",
      "\tConv2D layer output(conv_block_4/conv_layer_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(conv_block_4/conv_layer_1) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(conv_block_4/conv_layer_0) shape: [1, 4, 4, 512]\n",
      "conv_block_3:\n",
      "\tDropout layer output(conv_block_3/dropout_layer_2) shape: [1, 4, 4, 256]\n",
      "\tMaxPool2D layer output(conv_block_3/max_pool_layer_2) shape: [1, 4, 4, 256]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_1) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_0) shape: [1, 8, 8, 256]\n",
      "conv_block_2:\n",
      "\tDropout layer output(conv_block_2/dropout_layer_1) shape: [1, 8, 8, 128]\n",
      "\tMaxPool2D layer output(conv_block_2/max_pool_layer_1) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(conv_block_2/conv_layer_1) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(conv_block_2/conv_layer_0) shape: [1, 16, 16, 128]\n",
      "conv_block_1:\n",
      "\tDropout layer output(conv_block_1/dropout_layer_1) shape: [1, 16, 16, 64]\n",
      "\tMaxPool2D layer output(conv_block_1/max_pool_layer_1) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(conv_block_1/conv_layer_1) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(conv_block_1/conv_layer_0) shape: [1, 32, 32, 64]\n",
      "MaxPool2D layer output(on_off_maxpool) shape: [1, 32, 32, 6]\n",
      "---------------------------------------------------------------------------\n",
      "Starting training for VGG15PlusPlusOffOn...\n",
      "Epoch 1/100: Train Loss: 2.0983, Val Loss: 1.8778, Val Acc: 0.2121, Time: 74.17s\n",
      "Epoch 2/100: Train Loss: 1.8497, Val Loss: 1.8408, Val Acc: 0.2807, Time: 70.22s\n",
      "Epoch 3/100: Train Loss: 1.6558, Val Loss: 1.4261, Val Acc: 0.4153, Time: 70.32s\n",
      "Epoch 4/100: Train Loss: 1.4205, Val Loss: 1.3008, Val Acc: 0.4959, Time: 70.20s\n",
      "Epoch 5/100: Train Loss: 1.2796, Val Loss: 1.2062, Val Acc: 0.5758, Time: 70.19s\n",
      "Epoch 6/100: Train Loss: 1.1475, Val Loss: 0.9967, Val Acc: 0.6485, Time: 70.01s\n",
      "Epoch 7/100: Train Loss: 1.0509, Val Loss: 0.9180, Val Acc: 0.6727, Time: 69.90s\n",
      "Epoch 8/100: Train Loss: 0.9617, Val Loss: 0.8674, Val Acc: 0.7017, Time: 69.99s\n",
      "Epoch 9/100: Train Loss: 0.9092, Val Loss: 0.8859, Val Acc: 0.6902, Time: 69.91s\n",
      "Epoch 10/100: Train Loss: 0.8507, Val Loss: 0.8277, Val Acc: 0.7258, Time: 69.99s\n",
      "Epoch 11/100: Train Loss: 0.8284, Val Loss: 0.7843, Val Acc: 0.7326, Time: 70.01s\n",
      "Epoch 12/100: Train Loss: 0.8139, Val Loss: 0.7717, Val Acc: 0.7513, Time: 69.98s\n",
      "Epoch 13/100: Train Loss: 0.7487, Val Loss: 0.7823, Val Acc: 0.7412, Time: 69.92s\n",
      "Epoch 14/100: Train Loss: 0.7396, Val Loss: 0.7669, Val Acc: 0.7525, Time: 69.94s\n",
      "Epoch 15/100: Train Loss: 0.7511, Val Loss: 0.7408, Val Acc: 0.7481, Time: 69.95s\n",
      "Epoch 16/100: Train Loss: 0.7294, Val Loss: 0.7596, Val Acc: 0.7584, Time: 69.97s\n",
      "Epoch 17/100: Train Loss: 0.6939, Val Loss: 0.7918, Val Acc: 0.7476, Time: 70.07s\n",
      "Epoch 18/100: Train Loss: 0.6825, Val Loss: 0.6892, Val Acc: 0.7725, Time: 69.97s\n",
      "Epoch 19/100: Train Loss: 0.6865, Val Loss: 0.6827, Val Acc: 0.7836, Time: 69.94s\n",
      "Epoch 20/100: Train Loss: 0.6629, Val Loss: 0.6467, Val Acc: 0.7843, Time: 69.94s\n",
      "Epoch 21/100: Train Loss: 0.6610, Val Loss: 0.6409, Val Acc: 0.7924, Time: 69.92s\n",
      "Epoch 22/100: Train Loss: 0.6724, Val Loss: 0.6798, Val Acc: 0.7764, Time: 70.01s\n",
      "Epoch 23/100: Train Loss: 0.6392, Val Loss: 0.6485, Val Acc: 0.7916, Time: 69.98s\n",
      "Epoch 24/100: Train Loss: 0.6247, Val Loss: 0.6219, Val Acc: 0.8033, Time: 69.94s\n",
      "Epoch 25/100: Train Loss: 0.6423, Val Loss: 0.6865, Val Acc: 0.7806, Time: 69.97s\n",
      "Epoch 26/100: Train Loss: 0.6125, Val Loss: 0.6296, Val Acc: 0.7994, Time: 69.97s\n",
      "Epoch 27/100: Train Loss: 0.6263, Val Loss: 0.6421, Val Acc: 0.7913, Time: 69.97s\n",
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 28/100: Train Loss: 0.4800, Val Loss: 0.5671, Val Acc: 0.8155, Time: 70.07s\n",
      "Epoch 29/100: Train Loss: 0.4504, Val Loss: 0.5288, Val Acc: 0.8314, Time: 70.08s\n",
      "Epoch 30/100: Train Loss: 0.4329, Val Loss: 0.5248, Val Acc: 0.8344, Time: 70.07s\n",
      "Epoch 31/100: Train Loss: 0.4289, Val Loss: 0.5320, Val Acc: 0.8328, Time: 70.05s\n",
      "Epoch 32/100: Train Loss: 0.4320, Val Loss: 0.5587, Val Acc: 0.8281, Time: 70.03s\n",
      "Epoch 33/100: Train Loss: 0.4141, Val Loss: 0.5284, Val Acc: 0.8344, Time: 69.99s\n",
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 34/100: Train Loss: 0.3272, Val Loss: 0.4712, Val Acc: 0.8564, Time: 70.03s\n",
      "Epoch 35/100: Train Loss: 0.2987, Val Loss: 0.4849, Val Acc: 0.8548, Time: 70.02s\n",
      "Epoch 36/100: Train Loss: 0.2959, Val Loss: 0.5145, Val Acc: 0.8436, Time: 70.12s\n",
      "Epoch 37/100: Train Loss: 0.2797, Val Loss: 0.4956, Val Acc: 0.8522, Time: 70.05s\n",
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 38/100: Train Loss: 0.2309, Val Loss: 0.4572, Val Acc: 0.8666, Time: 70.06s\n",
      "Epoch 39/100: Train Loss: 0.2158, Val Loss: 0.4877, Val Acc: 0.8613, Time: 70.04s\n",
      "Epoch 40/100: Train Loss: 0.2090, Val Loss: 0.4713, Val Acc: 0.8637, Time: 70.14s\n",
      "Epoch 41/100: Train Loss: 0.2079, Val Loss: 0.4861, Val Acc: 0.8599, Time: 70.32s\n",
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 42/100: Train Loss: 0.1761, Val Loss: 0.4588, Val Acc: 0.8740, Time: 70.72s\n",
      "Epoch 43/100: Train Loss: 0.1629, Val Loss: 0.4542, Val Acc: 0.8730, Time: 70.18s\n",
      "Epoch 44/100: Train Loss: 0.1599, Val Loss: 0.4518, Val Acc: 0.8723, Time: 70.11s\n",
      "Epoch 45/100: Train Loss: 0.1583, Val Loss: 0.4548, Val Acc: 0.8754, Time: 70.10s\n",
      "Epoch 46/100: Train Loss: 0.1486, Val Loss: 0.4606, Val Acc: 0.8715, Time: 70.10s\n",
      "Epoch 47/100: Train Loss: 0.1437, Val Loss: 0.4759, Val Acc: 0.8712, Time: 70.05s\n",
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 48/100: Train Loss: 0.1317, Val Loss: 0.4634, Val Acc: 0.8772, Time: 70.11s\n",
      "Current lr= 3.125e-05 Updated lr= 1.5625e-05\n",
      "Epoch 49/100: Train Loss: 0.1242, Val Loss: 0.4608, Val Acc: 0.8765, Time: 70.16s\n",
      "Current lr= 1.5625e-05 Updated lr= 7.8125e-06\n",
      "Epoch 50/100: Train Loss: 0.1163, Val Loss: 0.4557, Val Acc: 0.8788, Time: 70.21s\n",
      "Epoch 51/100: Train Loss: 0.1177, Val Loss: 0.4554, Val Acc: 0.8776, Time: 70.11s\n",
      "Epoch 52/100: Train Loss: 0.1140, Val Loss: 0.4587, Val Acc: 0.8775, Time: 69.99s\n",
      "Epoch 53/100: Train Loss: 0.1076, Val Loss: 0.4617, Val Acc: 0.8789, Time: 70.03s\n",
      "Epoch 54/100: Train Loss: 0.1122, Val Loss: 0.4581, Val Acc: 0.8804, Time: 70.08s\n",
      "Current lr= 7.8125e-06 Updated lr= 3.90625e-06\n",
      "Epoch 55/100: Train Loss: 0.1076, Val Loss: 0.4604, Val Acc: 0.8794, Time: 70.28s\n",
      "Epoch 56/100: Train Loss: 0.1069, Val Loss: 0.4585, Val Acc: 0.8794, Time: 70.16s\n",
      "Epoch 57/100: Train Loss: 0.1069, Val Loss: 0.4607, Val Acc: 0.8798, Time: 70.13s\n",
      "Current lr= 3.90625e-06 Updated lr= 1.953125e-06\n",
      "Epoch 58/100: Train Loss: 0.1073, Val Loss: 0.4608, Val Acc: 0.8782, Time: 70.19s\n",
      "Finished training after 58 epochs!\n",
      "Training completed in 4068.14 seconds (67.80 minutes)\n",
      "VGG15PlusPlusOffOn Test Accuracy: 0.8762\n",
      "Saved results for VGG15PlusPlusOffOn\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "results = []\n",
    "all_models = [\"VGG15PlusPlusOffOn\"]\n",
    "# all_models = [\"VGG15PlusPlus\", \"VGG15PlusPlusOffOn\"]\n",
    "# get dataset with validation split\n",
    "x_train, y_train, x_val, y_val, x_test, y_test, classnames = get_dataset('cifar10', val_prop=0.2)\n",
    "\n",
    "# loop through each model to train\n",
    "for model_idx, model_type in enumerate(all_models):\n",
    "    # clear session to free memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    current_seed = SEED + model_idx\n",
    "    tf.random.set_seed(current_seed)\n",
    "    np.random.seed(current_seed)\n",
    "    \n",
    "    print(f\"\\n{'='*20} Training {model_type} {'='*20}\")\n",
    "    \n",
    "    if model_type == \"VGG4Plus\":\n",
    "        model = VGG4Plus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15\":\n",
    "        model = VGG15(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15Plus\":\n",
    "        model = VGG15Plus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15PlusPlus\":\n",
    "        model = VGG15PlusPlus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15PlusPlus\":\n",
    "        model = VGG15PlusPlus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15PlusPlusOffOn\":\n",
    "        model = VGG15PlusPlusOffOn(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    \n",
    "    # compile with AdamW optimizer\n",
    "    model.compile(optimizer='adamw')\n",
    "    \n",
    "    # train the model\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting training for {model_type}...\")\n",
    "    \n",
    "    train_loss_hist, val_loss_hist, val_acc_hist, epochs = model.fit(\n",
    "        x_train, y_train, \n",
    "        x_val, y_val, \n",
    "        max_epochs=100,\n",
    "        patience=15,\n",
    "        lr_patience=4,\n",
    "        verbose=True,\n",
    "        lr_decay_factor=0.5,\n",
    "        lr_max_decays=12\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # evaluate on test set\n",
    "    test_acc, test_loss = model.evaluate(x_test, y_test)\n",
    "    print(f\"{model_type} Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    result = {\n",
    "        'model_type': model_type,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'train_loss_history': train_loss_hist,\n",
    "        'val_loss_history': val_loss_hist,\n",
    "        'val_acc_history': val_acc_hist,\n",
    "        'epochs': epochs,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    # Save individual results in case notebook crashes\n",
    "    np.save(f\"{model_type}_results_10b.npy\", result)\n",
    "    print(f\"Saved results for {model_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Training VGG15PlusPlus ====================\n",
      "---------------------------------------------------------------------------\n",
      "Dense layer output(output) shape: [1, 10]\n",
      "dense_block:\n",
      "\tDropout layer output(dense_block/dropout_layer_0) shape: [1, 512]\n",
      "\tDense layer output(dense_block/dense_layer_0) shape: [1, 512]\n",
      "Flatten layer output(flatten) shape: [1, 512]\n",
      "conv_block_5:\n",
      "\tDropout layer output(conv_block_5/dropout_layer_2) shape: [1, 1, 1, 512]\n",
      "\tMaxPool2D layer output(conv_block_5/max_pool_layer_2) shape: [1, 1, 1, 512]\n",
      "\tConv2D layer output(conv_block_5/conv_layer_2) shape: [1, 2, 2, 512]\n",
      "\tConv2D layer output(conv_block_5/conv_layer_1) shape: [1, 2, 2, 512]\n",
      "\tConv2D layer output(conv_block_5/conv_layer_0) shape: [1, 2, 2, 512]\n",
      "conv_block_4:\n",
      "\tDropout layer output(conv_block_4/dropout_layer_2) shape: [1, 2, 2, 512]\n",
      "\tMaxPool2D layer output(conv_block_4/max_pool_layer_2) shape: [1, 2, 2, 512]\n",
      "\tConv2D layer output(conv_block_4/conv_layer_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(conv_block_4/conv_layer_1) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(conv_block_4/conv_layer_0) shape: [1, 4, 4, 512]\n",
      "conv_block_3:\n",
      "\tDropout layer output(conv_block_3/dropout_layer_2) shape: [1, 4, 4, 256]\n",
      "\tMaxPool2D layer output(conv_block_3/max_pool_layer_2) shape: [1, 4, 4, 256]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_1) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(conv_block_3/conv_layer_0) shape: [1, 8, 8, 256]\n",
      "conv_block_2:\n",
      "\tDropout layer output(conv_block_2/dropout_layer_1) shape: [1, 8, 8, 128]\n",
      "\tMaxPool2D layer output(conv_block_2/max_pool_layer_1) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(conv_block_2/conv_layer_1) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(conv_block_2/conv_layer_0) shape: [1, 16, 16, 128]\n",
      "conv_block_1:\n",
      "\tDropout layer output(conv_block_1/dropout_layer_1) shape: [1, 16, 16, 64]\n",
      "\tMaxPool2D layer output(conv_block_1/max_pool_layer_1) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(conv_block_1/conv_layer_1) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(conv_block_1/conv_layer_0) shape: [1, 32, 32, 64]\n",
      "---------------------------------------------------------------------------\n",
      "Starting training for VGG15PlusPlus...\n",
      "Epoch 1/100: Train Loss: 2.1382, Val Loss: 1.9001, Val Acc: 0.1923, Time: 72.50s\n",
      "Epoch 2/100: Train Loss: 1.8708, Val Loss: 1.7480, Val Acc: 0.3016, Time: 70.28s\n",
      "Epoch 3/100: Train Loss: 1.6432, Val Loss: 1.4899, Val Acc: 0.3878, Time: 69.96s\n",
      "Epoch 4/100: Train Loss: 1.4719, Val Loss: 1.3464, Val Acc: 0.4864, Time: 69.91s\n",
      "Epoch 5/100: Train Loss: 1.3090, Val Loss: 1.2662, Val Acc: 0.5428, Time: 69.86s\n",
      "Epoch 6/100: Train Loss: 1.1801, Val Loss: 1.0155, Val Acc: 0.6508, Time: 69.81s\n",
      "Epoch 7/100: Train Loss: 1.0529, Val Loss: 0.9476, Val Acc: 0.6736, Time: 69.82s\n",
      "Epoch 8/100: Train Loss: 0.9966, Val Loss: 0.9229, Val Acc: 0.6820, Time: 69.76s\n",
      "Epoch 9/100: Train Loss: 0.9111, Val Loss: 0.8773, Val Acc: 0.6946, Time: 69.69s\n",
      "Epoch 10/100: Train Loss: 0.8555, Val Loss: 0.8014, Val Acc: 0.7357, Time: 69.78s\n",
      "Epoch 11/100: Train Loss: 0.8344, Val Loss: 0.7555, Val Acc: 0.7468, Time: 69.64s\n",
      "Epoch 12/100: Train Loss: 0.8174, Val Loss: 0.7346, Val Acc: 0.7556, Time: 69.57s\n",
      "Epoch 13/100: Train Loss: 0.7748, Val Loss: 0.7016, Val Acc: 0.7637, Time: 69.64s\n",
      "Epoch 14/100: Train Loss: 0.7585, Val Loss: 0.7634, Val Acc: 0.7427, Time: 69.67s\n",
      "Epoch 15/100: Train Loss: 0.7496, Val Loss: 0.7639, Val Acc: 0.7522, Time: 69.53s\n",
      "Epoch 16/100: Train Loss: 0.7491, Val Loss: 0.7200, Val Acc: 0.7691, Time: 69.70s\n",
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 17/100: Train Loss: 0.5707, Val Loss: 0.6294, Val Acc: 0.7967, Time: 69.61s\n",
      "Epoch 18/100: Train Loss: 0.5413, Val Loss: 0.6022, Val Acc: 0.8047, Time: 69.48s\n",
      "Epoch 19/100: Train Loss: 0.5353, Val Loss: 0.5753, Val Acc: 0.8108, Time: 69.64s\n",
      "Epoch 20/100: Train Loss: 0.5227, Val Loss: 0.5675, Val Acc: 0.8191, Time: 69.58s\n",
      "Epoch 21/100: Train Loss: 0.5055, Val Loss: 0.5527, Val Acc: 0.8139, Time: 69.64s\n",
      "Epoch 22/100: Train Loss: 0.5147, Val Loss: 0.5565, Val Acc: 0.8181, Time: 69.55s\n",
      "Epoch 23/100: Train Loss: 0.4943, Val Loss: 0.6127, Val Acc: 0.8046, Time: 69.58s\n",
      "Epoch 24/100: Train Loss: 0.4835, Val Loss: 0.5305, Val Acc: 0.8299, Time: 69.50s\n",
      "Epoch 25/100: Train Loss: 0.4754, Val Loss: 0.5431, Val Acc: 0.8214, Time: 69.59s\n",
      "Epoch 26/100: Train Loss: 0.4634, Val Loss: 0.5437, Val Acc: 0.8227, Time: 69.60s\n",
      "Epoch 27/100: Train Loss: 0.4607, Val Loss: 0.5564, Val Acc: 0.8227, Time: 69.56s\n",
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 28/100: Train Loss: 0.3720, Val Loss: 0.5110, Val Acc: 0.8416, Time: 69.58s\n",
      "Epoch 29/100: Train Loss: 0.3412, Val Loss: 0.4750, Val Acc: 0.8478, Time: 69.47s\n",
      "Epoch 30/100: Train Loss: 0.3415, Val Loss: 0.4775, Val Acc: 0.8477, Time: 69.66s\n",
      "Epoch 31/100: Train Loss: 0.3295, Val Loss: 0.4742, Val Acc: 0.8496, Time: 69.60s\n",
      "Epoch 32/100: Train Loss: 0.3199, Val Loss: 0.4994, Val Acc: 0.8466, Time: 69.63s\n",
      "Epoch 33/100: Train Loss: 0.3195, Val Loss: 0.5137, Val Acc: 0.8456, Time: 69.68s\n",
      "Epoch 34/100: Train Loss: 0.3058, Val Loss: 0.4883, Val Acc: 0.8452, Time: 69.62s\n",
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 35/100: Train Loss: 0.2575, Val Loss: 0.4700, Val Acc: 0.8601, Time: 69.64s\n",
      "Epoch 36/100: Train Loss: 0.2360, Val Loss: 0.4683, Val Acc: 0.8607, Time: 69.60s\n",
      "Epoch 37/100: Train Loss: 0.2323, Val Loss: 0.4819, Val Acc: 0.8564, Time: 69.53s\n",
      "Epoch 38/100: Train Loss: 0.2275, Val Loss: 0.4863, Val Acc: 0.8587, Time: 69.60s\n",
      "Epoch 39/100: Train Loss: 0.2166, Val Loss: 0.5190, Val Acc: 0.8513, Time: 69.67s\n",
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 40/100: Train Loss: 0.1832, Val Loss: 0.4970, Val Acc: 0.8604, Time: 69.58s\n",
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 41/100: Train Loss: 0.1697, Val Loss: 0.4574, Val Acc: 0.8677, Time: 69.78s\n",
      "Epoch 42/100: Train Loss: 0.1626, Val Loss: 0.4586, Val Acc: 0.8677, Time: 69.60s\n",
      "Epoch 43/100: Train Loss: 0.1541, Val Loss: 0.4617, Val Acc: 0.8673, Time: 69.64s\n",
      "Epoch 44/100: Train Loss: 0.1536, Val Loss: 0.4607, Val Acc: 0.8688, Time: 69.72s\n",
      "Current lr= 3.125e-05 Updated lr= 1.5625e-05\n",
      "Epoch 45/100: Train Loss: 0.1446, Val Loss: 0.4638, Val Acc: 0.8687, Time: 69.66s\n",
      "Current lr= 1.5625e-05 Updated lr= 7.8125e-06\n",
      "Epoch 46/100: Train Loss: 0.1374, Val Loss: 0.4650, Val Acc: 0.8711, Time: 69.56s\n",
      "Epoch 47/100: Train Loss: 0.1372, Val Loss: 0.4691, Val Acc: 0.8701, Time: 69.67s\n",
      "Current lr= 7.8125e-06 Updated lr= 3.90625e-06\n",
      "Epoch 48/100: Train Loss: 0.1409, Val Loss: 0.4678, Val Acc: 0.8685, Time: 69.67s\n",
      "Current lr= 3.90625e-06 Updated lr= 1.953125e-06\n",
      "Epoch 49/100: Train Loss: 0.1357, Val Loss: 0.4640, Val Acc: 0.8687, Time: 69.71s\n",
      "Epoch 50/100: Train Loss: 0.1300, Val Loss: 0.4659, Val Acc: 0.8682, Time: 69.59s\n",
      "Epoch 51/100: Train Loss: 0.1351, Val Loss: 0.4659, Val Acc: 0.8687, Time: 69.69s\n",
      "Epoch 52/100: Train Loss: 0.1331, Val Loss: 0.4660, Val Acc: 0.8685, Time: 69.74s\n",
      "Current lr= 1.953125e-06 Updated lr= 9.765625e-07\n",
      "Epoch 53/100: Train Loss: 0.1353, Val Loss: 0.4649, Val Acc: 0.8679, Time: 69.78s\n",
      "Epoch 54/100: Train Loss: 0.1389, Val Loss: 0.4633, Val Acc: 0.8680, Time: 69.68s\n",
      "Epoch 55/100: Train Loss: 0.1282, Val Loss: 0.4643, Val Acc: 0.8689, Time: 69.60s\n",
      "Finished training after 55 epochs!\n",
      "Training completed in 3834.41 seconds (63.91 minutes)\n",
      "VGG15PlusPlus Test Accuracy: 0.8683\n",
      "Saved results for VGG15PlusPlus\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "results = []\n",
    "all_models = [\"VGG15PlusPlus\"]\n",
    "# all_models = [\"VGG15PlusPlus\", \"VGG15PlusPlusOffOn\"]\n",
    "# get dataset with validation split\n",
    "x_train, y_train, x_val, y_val, x_test, y_test, classnames = get_dataset('cifar10', val_prop=0.2)\n",
    "\n",
    "# loop through each model to train\n",
    "for model_idx, model_type in enumerate(all_models):\n",
    "    # clear session to free memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    current_seed = SEED + model_idx\n",
    "    tf.random.set_seed(current_seed)\n",
    "    np.random.seed(current_seed)\n",
    "    \n",
    "    print(f\"\\n{'='*20} Training {model_type} {'='*20}\")\n",
    "    \n",
    "    if model_type == \"VGG4Plus\":\n",
    "        model = VGG4Plus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15\":\n",
    "        model = VGG15(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15Plus\":\n",
    "        model = VGG15Plus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15PlusPlus\":\n",
    "        model = VGG15PlusPlus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15PlusPlus\":\n",
    "        model = VGG15PlusPlus(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    elif model_type == \"VGG15PlusPlusOffOn\":\n",
    "        model = VGG15PlusPlusOffOn(C=10, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "    \n",
    "    # compile with AdamW optimizer\n",
    "    model.compile(optimizer='adamw')\n",
    "    \n",
    "    # train the model\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting training for {model_type}...\")\n",
    "    \n",
    "    train_loss_hist, val_loss_hist, val_acc_hist, epochs = model.fit(\n",
    "        x_train, y_train, \n",
    "        x_val, y_val, \n",
    "        max_epochs=100,\n",
    "        patience=15,\n",
    "        lr_patience=4,\n",
    "        verbose=True,\n",
    "        lr_decay_factor=0.5,\n",
    "        lr_max_decays=12\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # evaluate on test set\n",
    "    test_acc, test_loss = model.evaluate(x_test, y_test)\n",
    "    print(f\"{model_type} Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    result = {\n",
    "        'model_type': model_type,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'train_loss_history': train_loss_hist,\n",
    "        'val_loss_history': val_loss_hist,\n",
    "        'val_acc_history': val_acc_hist,\n",
    "        'epochs': epochs,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    # Save individual results in case notebook crashes\n",
    "    np.save(f\"{model_type}_results_10b.npy\", result)\n",
    "    print(f\"Saved results for {model_type}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
